---
title: "p8105_hw6_jt3387"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(pheatmap)
library(ggcorrplot)
library(leaps)
library(patchwork)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

## Problem 2

Load and clean the data set.

```{r}
raw_data <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
homicide <- raw_data %>% 
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, state, sep = ", "),
         resolution = if_else(disposition == "Closed by arrest", 1, 0),
         victim_age = as.numeric(victim_age)) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
         victim_race %in% c("White", "Black"))
```

Fit a logistic regression model for city of Baltimore, MD.

```{r}
baltimore_df = homicide %>%
  filter(city_state == "Baltimore, MD")

baltimore_glm = 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial, data = baltimore_df) %>%
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         CI_lower = exp(estimate - 1.96 * std.error),
         CI_upper = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>%
  select(term, OR, CI_lower, CI_upper)

baltimore_glm %>% 
  knitr::kable(digits = 3)
```

- The estimate value of the adjusted odds ratio is 0.426, the confidence interval is (0.325, 0.558).

Run glm for each of the cities.

```{r}
all_city_glm = homicide %>% 
  nest(data = -city_state) %>% 
  mutate(model = map(data, ~glm(resolution ~ victim_age + victim_sex + victim_race, 
                                family = binomial, data = .x)), 
         tidy_result = map(model, broom::tidy)) %>% 
  select(city_state, tidy_result) %>% 
  unnest(tidy_result) %>%
  mutate(OR = exp(estimate), 
         CI_lower = exp(estimate - 1.96 * std.error), 
         CI_upper = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, OR, CI_lower, CI_upper)
all_city_glm %>% 
  knitr::kable(digits = 3)
```

Create a plot that shows the estimated ORs and CIs for each city.

```{r}
all_city_glm %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  labs(title = "Estimated OR and CI for Each City",
       x = "City, State",
       y = "Estimated Odds Ratio") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Comments on the plot:

- Most of the cities has a estimated odds ratio below 1, which indicates homicides with male victim have lower chance to be resolved than those with female victim.

- New York, NY has the lowest estimated odds ratio and a relatively narrow CI, while Albuquerque, NM has the highest estimated odds ratio and a relatively broad CI among all cities.

- Some cities' confidence intervals contain 1, so there is no significant difference in chance of solving the homicides with male or female victims at 0.05 significant level. Also, some cities have fairly broad confidence intervals which indicates dispersion in the data, so the estimated result must be interpreted with caution.

## Problem 3

Load, clean, and have a overview of the data set.

```{r message = FALSE}
birthweight <-read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(babysex = factor(recode(babysex, `1` = "Male", `2` = "Female")),
         frace = factor(recode(frace, `1` = "White", `2` = "Black", `3` = "Asian",
                        `4` = "Puerto Rican", `8` = "Other", `9` = "Unknown")),
         malform = factor(recode(malform, `0` = "Absent", `1` = "Present")),
         mrace = factor(recode(mrace, `1` = "White", `2` = "Black", `3` = "Asian",
                               `4` = "Puerto Rican", `8` = "Other")))
skimr::skim(birthweight)
```

- I converted four variables: `babysex`, `frace`, `malform`, `mrace` into factors and recoded their values to the associated levels, then checked for missing data and the result indicated that there is no missing data.

Have a overview of the statistics of variables.

```{r}
summary(birthweight)
```

-  We can find that there are only 0 values in variables `pnumlbw` and `pnumsga`, for variable `parity`, only 3 values are not 0 while other 4339 values are all 0, and variable `malform` has the similar situation. Therefore, they are not suitable to be predictors for regression. 

Check the distribution of the outcome to see whether it satisfies the normality assumption and whether it needs transformation.

```{r message = FALSE}
birthweight %>% ggplot(aes(x = bwt)) + 
  geom_histogram(aes(y = ..density..), fill = "light blue") +
  geom_density() + 
  labs(title = "Birthweight Distribution",
       x = "Birthweight (grams)",
       y = "Density")
```

- From the distribution curve, we can see that the distribution of `bwt` is roughly normal. Therefore, we think that it satisfies the normal assumption.

Draw a correlation coefficient matrix to see the relationship between different variables.

```{r}
cor <- birthweight %>% 
  select(2:6, 8, 10:12, 17:20) %>% 
  cor() %>% 
  round(3)
ggcorrplot(cor, type = "lower", hc.order = TRUE, lab = TRUE, lab_size = 3) + 
  guides(fill = guide_legend(title = "Pearson\nCorrelation"))
```

- From the correlation coefficient matrix, we can see that the correlation coefficients between some variables are very large such as `delwt` and `ppwt`, `ppbmi` and `ppwt`, so introducing all of them into the regression model will result in multicollinearity problems. 

Use boxplot to check the distribution of variables.

```{r}
pivotdata <- birthweight %>% 
  select(2, 3, 5, 6, 8, 10:12, 17:20) %>% 
  pivot_longer(everything(),
               names_to = "variable",
               values_to = "value")

pivotdata %>% 
  ggplot(aes(factor(variable), value)) + 
  geom_boxplot(
    aes(color = variable), 
    show.legend = FALSE, outlier.size = .8) + 
  facet_wrap(~variable, scale = "free") + 
  labs(title = "Boxplots of 12 numeric variables",
       x = "Variable",
       y = "Value")
```

- From the boxplot, we can see that many variables' IQR is not large and there are also outliers in them.

Have a overview of the preliminary model based on a hypothesized structure for the factors that underly birthweight and previous analysis, and find a better subset using `regsubsets` function.

```{r}
pre_model = lm(bwt ~ babysex + bhead + blength + frace + gaweeks + mheight + momage + mrace + smoken + wtgain, data = birthweight)
summary(pre_model) %>% 
  broom::tidy()
```

- From the regression result, we can see that, the coefficients of variables `frace`, `momage`, and `mrace` are not statistically significant, which all have p-values greater than 0.05.

```{r}
subset_model = regsubsets(bwt ~ babysex + bhead + blength + frace + gaweeks + mheight + momage + mrace + smoken + wtgain, data = birthweight)
subset_model_sum = summary(subset_model)
subset_model_sum

cp_bic_r_df = data.frame(c(1:8), subset_model_sum$cp, subset_model_sum$bic, subset_model_sum$adjr2)
p_cp <- ggplot() + 
  geom_line(data = cp_bic_r_df, aes(x = c.1.8., y = subset_model_sum.cp), size = 1) +
  geom_point(data = cp_bic_r_df, aes(x = c.1.8.,y = subset_model_sum.cp), size = 3) + 
  labs(title = "Cp of models",
       x = "Model",
       y = "Cp")
p_bic <- ggplot() +
  geom_line(data = cp_bic_r_df, aes(x = c.1.8., y = subset_model_sum.bic), size = 1) + 
  geom_point(data = cp_bic_r_df, aes(x = c.1.8., y = subset_model_sum.bic), size = 3) +
  labs(title = "BIC of models",
       x = "Model",
       y = "BIC")
p_adjr2 <- ggplot() +
  geom_line(data = cp_bic_r_df, aes(x = c.1.8., y = subset_model_sum.adjr2), size = 1) + 
  geom_point(data = cp_bic_r_df, aes(x = c.1.8., y = subset_model_sum.adjr2), size = 3) +
  labs(title = "Adjusted R2 of models",
       x = "Model",
       y = "Adjusted R2")
p_cp + p_bic + p_adjr2
```

- From the Cp, BIC, adjusted r2 plot, we can see that the 8th model has the highest adjusted r2 and lowest Cp and BIC. Therefore, we choose model 8 as our final model. The model contains variables: `babysex`, `bhead`, `blength`, `gaweeks`, `mheight`, `mrace`, `smoken`, and `wtgain`, so we excluded `frace` and `momage` from the preliminary model.

```{r}
final_model = lm(bwt ~ babysex + bhead + blength + gaweeks + mheight + mrace + smoken + wtgain, data = birthweight)
summary(final_model) %>% 
  broom::tidy()
```

Draw a plot of model residuals against fitted values.

```{r message = FALSE}
birthweight %>% 
  add_predictions(final_model) %>% 
  add_residuals(final_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(se = FALSE) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + 
  labs(title = "Residuals vs Fitted",
       x = "Fitted Values",
       y = "Residuals")
```

Modeling process:

- Clean the data set including convert variables format and check missing values.

- Check the distribution of the outcome `bwt`, and find that it follows normal distribution.

- Draw a correlation coefficient matrix to see the relationship between variables and the boxplot to check the distribution and outliers of every quantitative variables.

- Build a linear regression model with variables of the initial selection, then use `regsubset` function to choose a best model of the subsets by maximizing adjusted r2 and minimizing Cp and BIC.

- Model diagnosis using residual vs fitted values plot.

Model comparisons

```{r}
birthweight_cv <- crossv_mc(birthweight, 100)

birthweight_cv <- birthweight_cv %>% 
  mutate(mod1 = map(train, ~lm(bwt ~ babysex + bhead + blength + gaweeks + mheight + mrace + 
                                 smoken + wtgain, data = .x)),
         mod2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         mod3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + 
                                 blength * babysex + bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_mod1 = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
         rmse_mod2 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)),
         rmse_mod3 = map2_dbl(mod3, test, ~rmse(model = .x, data = .y)))

birthweight_cv %>% 
  select(c(7:9)) %>% 
  pivot_longer(everything(),
               names_to = "model",
               values_to = "rmse",
               names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin(alpha = 0.3) + 
  labs(title = "Model Comparison",
       x = "Model",
       y = "Rmse")
```

- From the violin plot, we can see that the model we choose has the lowest prediction error compared to the other two models. The second model with baby length and gestational age as predictors performs the worst which has the highest Rmse overall, and the interaction model is in the middle.